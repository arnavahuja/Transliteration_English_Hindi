{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transliteration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJ7sDhreSxEpikzZiA75hB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnavahuja/Transliteration_English_Hindi/blob/master/Transliteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lXI8Hq2FgfL",
        "colab_type": "text"
      },
      "source": [
        "Initial Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sjV37DcFf-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML,clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00cEWH0PHH3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_gpu = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nezUxebDF_mU",
        "colab_type": "text"
      },
      "source": [
        "Basic Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0MSnI2hEOpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e3b3c56c-ca3b-4178-cbd5-bcfb3073b0d0"
      },
      "source": [
        "\"\"\"Creating a dictionary for the english characters to be used later including a pad character\"\"\"\n",
        "\n",
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char:0}\n",
        "for index,alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "#print(eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVgbxa90EeYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e220fb36-2a6c-4adc-ff76-d2518d07d184"
      },
      "source": [
        "\"\"\"Creating a dictionary for the hindi characters to be used later including a pad character\"\"\"\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304,2432)]            #The hindi alphabets are in the ascii range 2304 to 2431\n",
        "hindi_alpha_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char:0}\n",
        "for index,alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "#print(hindi_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh9UdrngEiDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')        #Using regular expressions package to remove all non english letters\n",
        "\n",
        "#removing all english non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-',' ').replace(',',' ').upper()       #replacing comma and hyphen with space and converting all to upper-case\n",
        "    line = non_eng_letters_regex.sub('',line)\n",
        "    return line.split()                 #returning a list of the words in the line\n",
        "\n",
        "#removing all hindi non_letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-',' ').replace(',',' ')               #replacing comma and hyphen with space\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char==' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()         #returning a list of the words in the line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_e8KIShEp8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransliterationDataloader(Dataset):\n",
        "    \"\"\"Creating a dataloader for the dataset. Here the dataset is in the form of XML files\"\"\"\n",
        "    \"\"\"Read the xml file as well as clean the dataset for any abnormalities\"\"\"\n",
        "    def __init__(self,filename):\n",
        "        self.eng_words, self.hindi_words = self.read_XmlDataset(filename,cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.eng_words[idx],self.hindi_words[idx]\n",
        "\n",
        "    def read_XmlDataset(self,filename,lang_vocab_cleaner):          #Takes vocab cleaner as argument for easy changing to a different language\n",
        "        transliterationCorpus = ET.parse(filename).getroot()        #Get the root of the xml tree \n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "        \n",
        "        for line in transliterationCorpus:                          #Iterating through the XML tree\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            if len(wordlist1) != len(wordlist2):                                #removing abnormalities \n",
        "                print('Skipping:',line[0].text,'-',line[1].text)\n",
        "                continue\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "        return lang1_words,lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))         #getting a random datapoint from the dataset\n",
        "    \n",
        "    def get_batch_from_array(self,batch_size,array):                            \n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "\n",
        "        if end>=len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
        "    \n",
        "    def get_batch(self,batch_size,post_process=True):                           #getting a batch from the dataset\n",
        "        eng_batch = self.get_batch_from_array(batch_size,self.eng_words)        \n",
        "        hindi_batch = self.get_batch_from_array(batch_size,self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size+1\n",
        "        \n",
        "        #Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index>=len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "        return eng_batch,hindi_batch\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwUfWO2rEsS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "9042c146-e2c2-4acf-fcad-ffdb9dc1c86e"
      },
      "source": [
        "train_data = TransliterationDataloader('NEWS2012TrainingEnHi13937.xml')         #Train Data\n",
        "test_data = TransliterationDataloader('NEWS2012RefEnHi1000.xml')                #Test Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping: BARHARWA JUNCTION - बरहरवा\n",
            "Skipping: STATE BNK TR - स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping: SOUTH ARLINGTON CHURCH OF CHRIST - साउथ अर्लिंग्टन\n",
            "Skipping: KING EDWARD VII - किंग एडवर्ड\n",
            "Skipping: DIBANG VALLEY - दिबंगवैली\n",
            "Skipping: ORDER OF VASA - ऑडर ऑफ़ द वासा\n",
            "Skipping: AZAMNAGAR ROAD - आज़मनगर\n",
            "Skipping: CAPE TOWN - केपटाउन\n",
            "Skipping: NEW ZEALAND - न्यूज़ीलैंड\n",
            "Skipping: SEA OF THE HEBRIDES - सी ऑफ हरब्रिड्‍स\n",
            "Skipping: RAMCOIND - राम्को इंड\n",
            "Skipping: KELVINGROVE ART GALLERY AND MUSEUM - केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping: AUSTRALIAN NATIONAL UNIVERSITY - ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping: JAHAN AARA - जहाँआरा\n",
            "Skipping: NAVABHARAT FERRO ALLOYS - नव भारत फ़ैरो अलॉय\n",
            "Skipping: RAMA LINGESHWARA - रामालिंगेश्वर\n",
            "Skipping: FAKHRUN NISA - फखरुन्निसा\n",
            "Skipping: REDIFF.COM INDIA LIMITED - रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping: OMKARNATH THAKUR - ओंकार नाथ ठाकुर\n",
            "Skipping: OPENTV - ओपन टीवी\n",
            "Skipping: ENVOY COMMUNICATIONS GROUP - एन्वॉय कम्युनिकेशंस\n",
            "Skipping: WAR OF THE HOLY LEAGUE - वार ऑफ होली लीग\n",
            "Skipping: VAPARAISO CHURCH OF CHRIST - व्हापरासिओ\n",
            "Skipping: PARIS CHARLES DE GAULLE - पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping: PARKWAY APOSTOLIC - पार्क वे अपोस्टोलिक\n",
            "Skipping: MAUNA LOA - मौनालोआ\n",
            "Skipping: MASS MUTUAL LIFE - मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping: STATS CHIPPAC - स्टेट्सचिपपैक\n",
            "Skipping: NEWFOUNDLAND - न्यू फाउंडलैंड\n",
            "Skipping: LONDONHEATHROW - लंदन हीथ्रो\n",
            "Skipping: RETALIX - रेटालिक्स लि.\n",
            "Skipping: SRISAILAM - श्री शैलम\n",
            "Skipping: KARA-KUM - काराकुम\n",
            "Skipping: WIND RIVER - विंडरिवर\n",
            "Skipping: NETAJI SUBHASH CHANDRA BOSE - नेताजी सुभाषचंद्र बोस\n",
            "Skipping: ROCKBROOK UNITED - रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping: WALTER SCOTT - वॉल्टरस्कॉट\n",
            "Skipping: COLOURPLUS FASHIONS - कलर प्लस फ़ैशन्स\n",
            "Skipping: BAL KRISHNA - बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P5ApymsEuec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Finding the tensor representation of an english/hindi word\"\"\"\n",
        "def word_rep(word,letter2index,device='cpu'):\n",
        "    rep = torch.zeros(len(word)+1,1,len(letter2index)).to(device)       #Shape = (length of word,batch_size(to be used later),total letters in dictionary)\n",
        "    for letter_index,letter in enumerate(word):\n",
        "        pos = letter2index[letter]              #getting representation of letter\n",
        "        rep[letter_index][0][pos]=1             #adding the letter to the word tensor\n",
        "    pad_pos = letter2index[pad_char]            #adding padding at the end\n",
        "    rep[letter_index+1][0][pad_pos]=1\n",
        "    return rep\n",
        "\n",
        "\"\"\"Finding the tensor representation of ground truth\"\"\"\n",
        "def gt_rep(word,letter2index,device='cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1,1],dtype=torch.long).to(device)\n",
        "    for letter_index,letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index+1][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkRYVqCWEwMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng,hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng,eng_alpha2index)\n",
        "#print(eng,eng_rep.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t7iPcgvEx_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hindi_gt = gt_rep(hindi,hindi_alpha2index)      \n",
        "#print(hindi,hindi_gt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qa4ndkuE5aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Applying model to an input and producing an output\"\"\"\n",
        "def infer(net,input,max_output_char=30,device='cpu'):\n",
        "    input_rep = word_rep(input,eng_alpha2index).to(device)\n",
        "    outputs = net(input_rep,max_output_char)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yyNM_bVE-uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"An encoder decoder model with attention for the transliteration tast using GRU\"\"\"\n",
        "\n",
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,hidden_size,output_size,verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention,self).__init__()         \n",
        "\n",
        "        self.hidden_size = hidden_size                                          #initializing the hidden size for the GRU\n",
        "        self.output_size = output_size                                          #initializing the output size for the GRU\n",
        "\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size,hidden_size)                  \n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2,hidden_size)\n",
        "\n",
        "        self.h2o = nn.Linear(hidden_size,output_size)                           #output of the encoder \n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.U = nn.Linear(self.hidden_size,self.hidden_size)                   #defining the matrices for adding attention \n",
        "        self.W = nn.Linear(self.hidden_size,self.hidden_size)\n",
        "        self.Vattn = nn.Linear(self.hidden_size,1)\n",
        "        self.out2hidden = nn.Linear(self.output_size,self.hidden_size)\n",
        "\n",
        "        self.verbose = verbose                                                  #variable for bookkeeping\n",
        "    \n",
        "    def forward(self,input,max_output_chars=MAX_OUTPUT_CHARS,device='cpu',ground_truth=None):\n",
        "\n",
        "        #encoder\n",
        "        encoder_outputs,hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1,self.hidden_size)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Encoder output-',encoder_outputs.shape)\n",
        "\n",
        "        #decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1,1,self.output_size).to(device)\n",
        "        outputs = []\n",
        "\n",
        "        U = self.U(encoder_outputs)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Decoder state- ',decoder_state.shape)\n",
        "            print('Decoder intermediate input- ',decoder_input.shape)\n",
        "            print('U * Encoder output- ',U.shape)\n",
        "            \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1,-1).repeat(encoder_outputs.shape[0],1))\n",
        "            V = self.Vattn(torch.tanh(W+U))\n",
        "            attn_weights = F.softmax(V.view(1,-1),dim=1)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('W * DecoderState- ',W.shape)\n",
        "                print('V- ',V.shape)\n",
        "                print('Attn- ',attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
        "\n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0],attn_applied[0]),1).unsqueeze(0)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Attn LC- ',attn_applied.shape)\n",
        "                print('Decoder Input',decoder_input.shape)\n",
        "\n",
        "            out,decoder_state = self.decoder_rnn_cell(decoder_input,decoder_state)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate input- ',out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1,-1))\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder output',out.shape)\n",
        "                self.verbose=False\n",
        "\n",
        "            max_idx = torch.argmax(out,2,keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1,1,1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "            decoder_input = one_hot.detach()\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IviLk58_FBl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index),256,len(hindi_alpha2index),verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iBmNxP0FB_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a08c0572-477e-43e2-95a9-bde99745639d"
      },
      "source": [
        "out = infer(net_attn,'INDIA',30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output- torch.Size([6, 256])\n",
            "Decoder state-  torch.Size([1, 1, 256])\n",
            "Decoder intermediate input-  torch.Size([1, 1, 129])\n",
            "U * Encoder output-  torch.Size([6, 256])\n",
            "W * DecoderState-  torch.Size([6, 256])\n",
            "V-  torch.Size([6, 1])\n",
            "Attn-  torch.Size([1, 6])\n",
            "Attn LC-  torch.Size([1, 1, 256])\n",
            "Decoder Input torch.Size([1, 1, 512])\n",
            "Decoder intermediate input-  torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ow6B6HFDxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "fe42921a-4a7b-4716-f417-2f73ea04dac3"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape,list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) क़\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n",
            "torch.Size([1, 129]) १\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qUFRiHgFGY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net,opt,criterion,batch_size,device='cpu',teacher_force=False):\n",
        "    \"\"\"Training the model for a batch of data for transliteration \"\"\"\n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch,hindi_batch = train_data.get_batch(batch_size)\n",
        "\n",
        "    total_loss=0\n",
        "    for i in range(batch_size):\n",
        "        input = word_rep(eng_batch[i],eng_alpha2index,device)                   #get the tensor representations of inputs\n",
        "        gt = gt_rep(hindi_batch[i],hindi_alpha2index,device)                    #get the tensor representations of ground truth\n",
        "        outputs = net(input,gt.shape[0],device,ground_truth=gt if teacher_force else None)\n",
        "\n",
        "        for index,output in enumerate(outputs):\n",
        "            loss = criterion(output,gt[index])/batch_size                       #find the loss using  negative logloss funciton\n",
        "            loss.backward(retain_graph=True)                                    \n",
        "            total_loss+=loss\n",
        "\n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbcYiqNHFNJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index),256,len(hindi_alpha2index),verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ERFvLyeFQcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net,device='cpu'):\n",
        "    \"\"\"Function for calculating the test accuracy\"\"\"\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng,hindi = test_data[i]\n",
        "        gt = gt_rep(hindi,hindi_alpha2index,device)\n",
        "        outputs = infer(net,eng,gt.shape[0],device)\n",
        "        correct = 0\n",
        "        for index,out in enumerate(outputs):\n",
        "            val,indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct+=1\n",
        "        accuracy+=correct/gt.shape[0]\n",
        "    accuracy/=len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE1l2DAQFS6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy_train(net,device='cpu'):\n",
        "    \"\"\"Funciton for calculating train accuracy\"\"\"\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(train_data)):                #iterating over the train data \n",
        "        eng,hindi = train_data[i]\n",
        "        gt = gt_rep(hindi,hindi_alpha2index,device)\n",
        "        outputs = infer(net,eng,gt.shape[0],device)\n",
        "        correct = 0\n",
        "        for index,out in enumerate(outputs):        \n",
        "            val,indices = out.topk(1)               #calculating accuracy using topk accuracy function. (k can be used as an input parameter)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct+=1\n",
        "        accuracy+=correct/gt.shape[0]\n",
        "    accuracy/=len(train_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCLc57CjFZ-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net,lr=0.01,n_batches=100,batch_size=10,momentum=0.9,display_freq=5,device='cpu'):\n",
        "    \"\"\"Function encompassing the entire train setup\"\"\"\n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index=-1)\n",
        "    opt = optim.Adam(net.parameters(),lr=lr,weight_decay=1e-5)       \n",
        "    teacher_force_upto = n_batches//100\n",
        "\n",
        "    loss_arr = np.zeros(n_batches+1)\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i +  train_batch(net,opt,criterion,batch_size,device=device,teacher_force=i<teacher_force_upto))/(i+1)\n",
        "\n",
        "        if i%display_freq==0:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            print('Iteration',i,'Loss',loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i],'-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "    torch.save(net,'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9AKvsWYFdth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = torch.load('Hindi_Eng_Model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOPeu72bFJuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index),256,len(hindi_alpha2index),verbose=True)\n",
        "#net_attn.to(device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0um8stYFVAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f91de4a-0cb0-46e0-8ea6-20372d7f69a5"
      },
      "source": [
        "accuracy = calc_accuracy(net_attn)*100\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.15793373293371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_xj89TmFOvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "ed0e2bd2-3103-4f05-c5f3-e3621f149886"
      },
      "source": [
        "train_setup(net_attn,lr=0.0001,n_batches=50,batch_size=64,display_freq=10,device=device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 40 Loss 0.06527220457792282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.05794512, 0.05595865, 0.05770024, 0.06199471,\n",
              "       0.06617172, 0.06388726, 0.06252144, 0.06423812, 0.06435689,\n",
              "       0.06540845, 0.06670225, 0.06442491, 0.06400037, 0.06373689,\n",
              "       0.06373794, 0.06377374, 0.06326185, 0.06339822, 0.06287321,\n",
              "       0.06314045, 0.06357741, 0.06378508, 0.06311057, 0.0629698 ,\n",
              "       0.06374419, 0.06329262, 0.06336671, 0.06406233, 0.06428452,\n",
              "       0.06473018, 0.06450854, 0.06442337, 0.06469156, 0.06469984,\n",
              "       0.06545281, 0.06549253, 0.06593499, 0.06593882, 0.06536441,\n",
              "       0.0652722 , 0.06480505, 0.06497199, 0.064827  , 0.06466226,\n",
              "       0.06477021, 0.06474963, 0.06465378, 0.06454672, 0.06468923,\n",
              "       0.06493166])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDym2f--jnhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}